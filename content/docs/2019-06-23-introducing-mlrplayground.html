---
title: "Introducing mlrPlayground"
authors: ["sebastian-gruber"]
date: '2019-06-09'
output:
  blogdown::html_page:
    toc: true
categories:
  - r-bloggers
tags:
  - shiny
  - visualization
  - mlr
  - teaching
  - classification
  - regression
  - hyperparameter
---



<p>(Gif of welcome area)</p>
<div id="first-of-all" class="section level4">
<h4>First of all, …</h4>
<p>… you may ask yourself how is this name ‘mlrPlayground’ even justified? What a mad man puts two such opposite terms in a single word and expects people to take him seriously? I assume most of you know ‘mlr’, for those who don’t: it’s a framework for machine learning tasks offering a huge variety of different learners based on the best packages available in R, it’s about productivity, simplicity, and extendability. Quite the opposite from a place, where you can play with your best friends, make new friends, live out your fantasies and just have a great time the whole day until your parents pick you up. Well, for most of the readers here this may not be the case anymore – we know, we are still young in our heart, but let’s be honest … For sure, we all have those memories and definitely have certain associations by the word ‘Playground’. So what is it then with this thing called ‘mlrPlayground’?</p>
</div>
<div id="the-idea" class="section level4">
<h4>The idea …</h4>
<p>… behind this project was to offer a platform in the form of a <a href="https://shiny.rstudio.com/">Shiny</a> web application, where a user can try out different kinds of learners provided by the mlr package on a small set of destinct and tunable regression and classification tasks, making it possible to observe the prediction behaviour based on changes on the task, the learner or its hyperparameters. In the best case the user will gain new insights and deeper understanding of how each learner works, where it’s advantages are and also very importantly the cases when the learner fails miserably. There are a lot of different settings we want to offer in the user interface, and so – to not remove the fun of our playground – a huge effort went into making the UI as aesthetically pleasing and as smooth as possible. To achieve this, a website template was downloaded from <a href="https://templated.co/">Templated</a> and used as a baseline for design. After extending the template with missing CSS classes, most of the used shiny widgets have been overwritten – or even completely replaced –, offering refreshingly new visuals for the well known shiny framework. For the smoothness part, an object oriented <a href="https://cran.r-project.org/web/packages/R6/index.html">R6</a> class system with reactive attributes was engineered for the backend to give a well-defined framework of which elements should trigger what evaluation; an otherwise extremely tiresome and error-prone task for dozens of different UI elements. After all ‘mlrPlayground’ may not be as fun as a real playground, but you are also not as likely to hurt yourself and it is definitely more entertaining than looking at boring pictures of learners in a book.</p>
</div>
<div id="features" class="section level4">
<h4>Features …</h4>
<p>… provided by this application are finally described in the following.</p>
<p>When running the app and scrolling down you can basically see two big boxes with content: the left one is for the task and learner settings, the right one for an overview of the learner’s bevahiour. For the first look it may be of help (even though not necessary) to explore the tasks. After finding the right button (I leave this task to the motivated reader) a panel with all available datasets is extended over our screen. Here, we can choose the tasktype of either classification with two covariables or regression with one covariable and several other parameters influencing the dataset: size, noise and the train/test split.</p>
<p>(Gif of task selection)</p>
<p>Back at the main panel we can then select a learner for our task – due to limited manpower not all available in mlr have made it into this selection, expect extensions in the future. Now, it may take a few seconds because several things are happening in the background:</p>
<ul>
<li><p>a model is trained on the training set</p></li>
<li><p>different kinds of performance measures are calculated on the test set</p></li>
<li><p>a grid of points is used for inference to create a plot showing the prediction surface as colored background shading with the original dataset plotted in the front.</p></li>
</ul>
<p>(Gif of learner selection)</p>
<p>The first visual change after calculations have finished is the appearance of the prediction plot and the availability of the performance measurements by clicking on the equally named bar on the right hand side.</p>
<p>(Gif of performance measure)</p>
<p>If you want to see the effect of hyperparameters on the plot/performance measures, simply click on the small cog next to the learner selection. Now, the left panel is replaced by a window with all available hyperparameters – changes of these have an immediate effect of recalculating the whole model and updating all plots/numbers.</p>
<p>(Gif of hyperparameter changes)</p>
<p>Only observing changes of a single learner may become a bit boring after time, so a small button is available to easily double the fun: Pressing “Add learner” gives the choice of a second learner with a second plot, making it possible to compare the prediction surfaces of two different learners on the same task right next of each other. Incredible.</p>
<p>(Gif of adding second learner)</p>
<p>But wait, there’s still more to offer!</p>
<p>The curious user can change the shown plots on the right panel by switching to the tabs “Learning Curve” (classification and regression) or “ROC curve” (only classification). The former tells you how well the learner does, or the learners do compared to each other, with respect to user selected performance measurements (y-axis) on a fraction of the original train data (x-axis). Every additionally selected measure gives an additional plot. Not groundbreaking, but handy.</p>
<p>(Gif of Learning Curve)</p>
<p>Last but not least, the ROC curve is only an ROC curve with its default settings for the x- and y-axis: Plotting the true positive rate against the false positive rate, giving good advice of how well the learner can separate the classes (the bigger the area under the curve, the better). Change the settings and you’ll get quite exotic variations, whose names are beyond the scope of the author.</p>
<p>(Gif of ROC)</p>
</div>
<div id="thanks" class="section level4">
<h4>Thanks …</h4>
<p>… for spending your time reading this blog post, instead of being on a real playground.</p>
</div>
